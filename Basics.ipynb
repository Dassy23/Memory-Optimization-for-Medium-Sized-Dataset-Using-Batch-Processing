{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Memory Optimization for Medium Sized Dataset Using Batch Processing\n",
    "\n",
    " I will be optimizing the Lending Club's website data from the timeframe of 2007-2011 with the assumption that I only have 10mb to process and analyze the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint as pp\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas library provides a very easy way to batch process the dataset using chunks. Below split the dataset into 1000 row chunks and determine the total memory footprint as well as the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory is 66.1424999237 mB\n",
      "Total Number of Rows is  42538\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv('loans_2007.csv',chunksize=1000)\n",
    "total_mem=0\n",
    "total_rows=0\n",
    "for chunk in chunk_iter:\n",
    "    total_mem+=chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    total_rows+=len(chunk)\n",
    "\n",
    "print('Total Memory is',total_mem,'mB')\n",
    "print('Total Number of Rows is ', total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the assumptions of this project is we only have 10mb of memory available to process and analyze this dataset. With a total memory footprint of 66mB we need to ensure each batch of data we process is around 5mb( approx half the 10mb limit, just to be safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6512298583984375\n",
      "4.6481781005859375\n",
      "4.6496686935424805\n",
      "4.6505937576293945\n",
      "4.6469202041625977\n",
      "4.6483755111694336\n",
      "4.6473674774169922\n",
      "4.6494159698486328\n",
      "4.647435188293457\n",
      "4.6472721099853516\n",
      "4.6598777770996094\n",
      "4.6566619873046875\n",
      "4.6634960174560547\n",
      "4.8978452682495117\n",
      "0.88080883026123047\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv('loans_2007.csv',chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    pp.pprint(chunk.memory_usage(deep=True).sum()/(1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42000</th>\n",
       "      <td>247286</td>\n",
       "      <td>247257.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4201.940000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.34%</td>\n",
       "      <td>197.40</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>Best Buy</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>1106.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>207.82</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42001</th>\n",
       "      <td>246996</td>\n",
       "      <td>244258.0</td>\n",
       "      <td>17250.0</td>\n",
       "      <td>17250.0</td>\n",
       "      <td>12150.005316</td>\n",
       "      <td>36 months</td>\n",
       "      <td>17.66%</td>\n",
       "      <td>620.70</td>\n",
       "      <td>G</td>\n",
       "      <td>G2</td>\n",
       "      <td>CVS PHARMACY</td>\n",
       "      <td>2 years</td>\n",
       "      <td>OWN</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>2065.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Nov-2008</td>\n",
       "      <td>621.01</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42002</th>\n",
       "      <td>246720</td>\n",
       "      <td>246706.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.13%</td>\n",
       "      <td>451.48</td>\n",
       "      <td>E</td>\n",
       "      <td>E4</td>\n",
       "      <td>General Motors</td>\n",
       "      <td>7 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>3253.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>470.66</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42003</th>\n",
       "      <td>246535</td>\n",
       "      <td>246427.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>5650.000000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>18.29%</td>\n",
       "      <td>435.58</td>\n",
       "      <td>G</td>\n",
       "      <td>G4</td>\n",
       "      <td>usa medical center</td>\n",
       "      <td>6 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>3680.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>450.84</td>\n",
       "      <td>Jun-2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42004</th>\n",
       "      <td>246197</td>\n",
       "      <td>217842.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3849.997562</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.08%</td>\n",
       "      <td>129.22</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>InvestSource Inc</td>\n",
       "      <td>4 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>582.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.67</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Mar-2010</td>\n",
       "      <td>129.22</td>\n",
       "      <td>Aug-2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "42000  247286   247257.0     6000.0       6000.0      4201.940000   36 months   \n",
       "42001  246996   244258.0    17250.0      17250.0     12150.005316   36 months   \n",
       "42002  246720   246706.0    13000.0      13000.0      7700.000000   36 months   \n",
       "42003  246535   246427.0    12000.0      12000.0      5650.000000   36 months   \n",
       "42004  246197   217842.0     4000.0       4000.0      3849.997562   36 months   \n",
       "\n",
       "      int_rate  installment grade sub_grade           emp_title emp_length  \\\n",
       "42000   11.34%       197.40     C        C2            Best Buy    3 years   \n",
       "42001   17.66%       620.70     G        G2        CVS PHARMACY    2 years   \n",
       "42002   15.13%       451.48     E        E4      General Motors    7 years   \n",
       "42003   18.29%       435.58     G        G4  usa medical center    6 years   \n",
       "42004   10.08%       129.22     B        B3    InvestSource Inc    4 years   \n",
       "\n",
       "      home_ownership  annual_inc verification_status    ...    total_rec_int  \\\n",
       "42000           RENT     32000.0        Not Verified    ...          1106.40   \n",
       "42001            OWN     62000.0        Not Verified    ...          2065.95   \n",
       "42002           RENT     78000.0        Not Verified    ...          3253.16   \n",
       "42003           RENT     62000.0        Not Verified    ...          3680.71   \n",
       "42004           RENT     48000.0        Not Verified    ...           582.00   \n",
       "\n",
       "      total_rec_late_fee recoveries collection_recovery_fee last_pymnt_d  \\\n",
       "42000                0.0       0.00                    0.00     Feb-2011   \n",
       "42001                0.0       0.00                    0.00     Nov-2008   \n",
       "42002                0.0       0.00                    0.00     Feb-2011   \n",
       "42003                0.0       0.00                    0.00     Feb-2011   \n",
       "42004                0.0      61.67                    0.85     Mar-2010   \n",
       "\n",
       "      last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
       "42000          207.82           Jun-2016                         0.0   \n",
       "42001          621.01           Jun-2016                         0.0   \n",
       "42002          470.66           Jun-2016                         0.0   \n",
       "42003          450.84           Jun-2011                         0.0   \n",
       "42004          129.22           Aug-2010                         0.0   \n",
       "\n",
       "       policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "42000          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "42001          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "42002          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "42003          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "42004          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "\n",
       "       delinq_amnt  pub_rec_bankruptcies tax_liens  \n",
       "42000          0.0                   NaN       0.0  \n",
       "42001          0.0                   NaN       0.0  \n",
       "42002          0.0                   NaN       0.0  \n",
       "42003          0.0                   NaN       0.0  \n",
       "42004          0.0                   NaN       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are a few questions we need answered about the data in each column. First what type of data is in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     21\n",
      "int64       1\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     22\n",
      "dtype: int64\n",
      "float64    30\n",
      "object     22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv('loans_2007.csv',chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    pp.pprint(chunk.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index(['id'], dtype='object')\n",
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv('loans_2007.csv',chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    print(chunk.select_dtypes(include=['int64']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we have 21 object columns and 31 numeric columns. One interesting thing that appears is that the 'ID' changes its dytpe from int64 to object. This should not make a major impact as the ID column is not that important in this project. Next I will check how many unique values are in each object column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Create dictionary (key: column, value: list of Series objects representing each chunk's value counts)\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "string_cols_values= {}\n",
    "for chunk in chunk_iter:\n",
    "    #select only the object columns\n",
    "    str_cols = chunk.select_dtypes(include=['object'])\n",
    "    for col in str_cols.columns:\n",
    "        #loop through each column and find the value counts\n",
    "        current_col_vc = str_cols[col].value_counts()\n",
    "        #save values to dictionary\n",
    "        if col in string_cols_values:\n",
    "            string_cols_values[col].append(current_col_vc)\n",
    "        else:\n",
    "            string_cols_values[col] = [current_col_vc]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have combined the unqiue values in each object column lets find out the count of NaN values in the float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pub_rec_bankruptcies',\n",
      " 'pub_rec_bankruptcies',\n",
      " 'member_id',\n",
      " 'loan_amnt',\n",
      " 'funded_amnt',\n",
      " 'funded_amnt_inv',\n",
      " 'installment',\n",
      " 'annual_inc',\n",
      " 'dti',\n",
      " 'delinq_2yrs',\n",
      " 'inq_last_6mths',\n",
      " 'open_acc',\n",
      " 'pub_rec',\n",
      " 'revol_bal',\n",
      " 'total_acc',\n",
      " 'out_prncp',\n",
      " 'out_prncp_inv',\n",
      " 'total_pymnt',\n",
      " 'total_pymnt_inv',\n",
      " 'total_rec_prncp',\n",
      " 'total_rec_int',\n",
      " 'total_rec_late_fee',\n",
      " 'recoveries',\n",
      " 'collection_recovery_fee',\n",
      " 'last_pymnt_amnt',\n",
      " 'collections_12_mths_ex_med',\n",
      " 'policy_code',\n",
      " 'acc_now_delinq',\n",
      " 'chargeoff_within_12_mths',\n",
      " 'delinq_amnt',\n",
      " 'pub_rec_bankruptcies',\n",
      " 'tax_liens',\n",
      " 'member_id',\n",
      " 'loan_amnt',\n",
      " 'funded_amnt',\n",
      " 'funded_amnt_inv',\n",
      " 'installment',\n",
      " 'annual_inc',\n",
      " 'dti',\n",
      " 'delinq_2yrs',\n",
      " 'inq_last_6mths',\n",
      " 'open_acc',\n",
      " 'pub_rec',\n",
      " 'revol_bal',\n",
      " 'total_acc',\n",
      " 'out_prncp',\n",
      " 'out_prncp_inv',\n",
      " 'total_pymnt',\n",
      " 'total_pymnt_inv',\n",
      " 'total_rec_prncp',\n",
      " 'total_rec_int',\n",
      " 'total_rec_late_fee',\n",
      " 'recoveries',\n",
      " 'collection_recovery_fee',\n",
      " 'last_pymnt_amnt',\n",
      " 'collections_12_mths_ex_med',\n",
      " 'policy_code',\n",
      " 'acc_now_delinq',\n",
      " 'chargeoff_within_12_mths',\n",
      " 'delinq_amnt',\n",
      " 'pub_rec_bankruptcies',\n",
      " 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "## Create dictionary (key: column, value: list of Series objects representing each chunk's value counts)\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "float_cols_values= {}\n",
    "float_nan=[]\n",
    "float_not_nan=[]\n",
    "for chunk in chunk_iter:\n",
    "    #select only the object columns\n",
    "    flt_cols = chunk.select_dtypes(include=['float'])\n",
    "    for col in flt_cols.columns:\n",
    "        #save cols with no nan values to list\n",
    "        if not chunk[col].isnull().any():\n",
    "            float_not_nan.append(col)\n",
    "        else:\n",
    "            float_nan.append(col)\n",
    "        float_cols_values.update({col:(len(chunk[col]) - chunk[col].count())})\n",
    "#pp.pprint(sorted(float_cols_values.items(), key=lambda x: x[1])) \n",
    "pp.pprint(float_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the datatypes for memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few object columns that we can convert to numeric with a bit of cleaning. The int_rate and revol_util can be converted by removing the percent sign. Can the term column can be converted by removing the months string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1684398651123047\n",
      "4.1656618118286133\n",
      "4.1671142578125\n",
      "4.1681051254272461\n",
      "4.1645698547363281\n",
      "4.1658296585083008\n",
      "4.1649141311645508\n",
      "4.1669502258300781\n",
      "4.1651468276977539\n",
      "4.1649971008300781\n",
      "4.177581787109375\n",
      "4.1744918823242188\n",
      "4.1814451217651367\n",
      "4.4157543182373047\n",
      "0.79541492462158203\n"
     ]
    }
   ],
   "source": [
    "chunk_iter=pd.read_csv('loans_2007.csv',chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    chunk['int_rate']= pd.to_numeric(chunk['int_rate'].str.rstrip(\"%\"))\n",
    "    chunk['revol_util']= pd.to_numeric(chunk['revol_util'].str.rstrip(\"%\")) \n",
    "    chunk['term']= pd.to_numeric(chunk['term'].str.lstrip(\" \").str.rstrip(\" months\"))\n",
    "    pp.pprint(chunk.memory_usage(deep=True).sum()/(1024*1024))                    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By converting the 3 columns above to numeric we have 11% memory consumption. Next I will convert the columns with minimal unique values to category columns and change the date columns to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7836942672729492\n",
      "2.7802896499633789\n",
      "2.7825155258178711\n",
      "2.7827301025390625\n",
      "2.7799167633056641\n",
      "2.7808027267456055\n",
      "2.7801380157470703\n",
      "2.782109260559082\n",
      "2.7805881500244141\n",
      "2.7818393707275391\n",
      "2.7946376800537109\n",
      "2.7933759689331055\n",
      "2.8010787963867188\n",
      "3.0340814590454102\n",
      "0.55158805847167969\n"
     ]
    }
   ],
   "source": [
    "cat_cols = {\n",
    "    \"sub_grade\": \"category\", \"home_ownership\": \"category\", \n",
    "    \"verification_status\": \"category\", \"purpose\": \"category\"\n",
    "}\n",
    "chunk_iter=pd.read_csv('loans_2007.csv',dtype = cat_cols, parse_dates=[\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"],chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    \n",
    "    chunk['int_rate']= pd.to_numeric(chunk['int_rate'].str.rstrip(\"%\"))\n",
    "    chunk['revol_util']= pd.to_numeric(chunk['revol_util'].str.rstrip(\"%\")) \n",
    "    chunk['term']= pd.to_numeric(chunk['term'].str.lstrip(\" \").str.rstrip(\" months\"))\n",
    "    \n",
    "    pp.pprint(chunk.memory_usage(deep=True).sum()/(1024*1024))   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The memory consumption has drastically dropped to approx 60% of the intial values. The final optimization will be to downcast the float columns with no NaN values to the optimal integer dtypes and the float columns with NaN values to the optimal float dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4403715133666992\n",
      "2.4369668960571289\n",
      "2.4391927719116211\n",
      "2.4394073486328125\n",
      "2.4365940093994141\n",
      "2.4374799728393555\n",
      "2.4368152618408203\n",
      "2.438786506652832\n",
      "2.4372653961181641\n",
      "2.4385166168212891\n",
      "2.4513149261474609\n",
      "2.4500532150268555\n",
      "2.4577560424804688\n",
      "2.6907587051391602\n",
      "0.49001884460449219\n"
     ]
    }
   ],
   "source": [
    "cat_cols = {\n",
    "    \"sub_grade\": \"category\", \"home_ownership\": \"category\", \n",
    "    \"verification_status\": \"category\", \"purpose\": \"category\"\n",
    "}\n",
    "chunk_iter=pd.read_csv('loans_2007.csv',dtype = cat_cols, parse_dates=[\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"],chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    \n",
    "    chunk['int_rate']= pd.to_numeric(chunk['int_rate'].str.rstrip(\"%\"))\n",
    "    chunk['revol_util']= pd.to_numeric(chunk['revol_util'].str.rstrip(\"%\")) \n",
    "    chunk['term']= pd.to_numeric(chunk['term'].str.lstrip(\" \").str.rstrip(\" months\"))\n",
    "    flt_cols = chunk.select_dtypes(include=['float'])\n",
    "    for col in flt_cols.columns:\n",
    "        if col in float_not_nan:\n",
    "            chunk[col]= pd.to_numeric(chunk[col], downcast='integer')\n",
    "        else:\n",
    "            chunk[col]= pd.to_numeric(chunk[col], downcast='float')\n",
    "    pp.pprint(chunk.memory_usage(deep=True).sum()/(1024*1024)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through optimizing the column datatypes I was able to drop the memory footprint to close to 50% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
